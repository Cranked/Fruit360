{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c80a83f7fb1ab87aabbdad97d11627fb0380e8f",
    "tags": []
   },
   "source": [
    "# Convolutional Neural Networks (CNN)\n",
    "<font color='blue'>\n",
    "<br>Content: \n",
    "* [Loading the Data Set](#1)\n",
    "* [Normalization, Reshape and Label Encoding ](#2)\n",
    "* [Train Test Split](#3)\n",
    "* [Convolutional Neural Network](#4)\n",
    "    * [What is Convolution Operation?](#5)\n",
    "    * [Same Padding](#6)\n",
    "    * [Max Pooling](#7)\n",
    "    * [Flattening](#8)\n",
    "    * [Full Connection](#9)\n",
    "* [Implementing with Keras](#10)\n",
    "    * [Create Model](#11)\n",
    "    * [Define Optimizer](#12)\n",
    "    * [Compile Model](#13)\n",
    "    * [Epochs and Batch Size](#14)\n",
    "    * [Data Augmentation](#15)\n",
    "    * [Fit the Model](#16)\n",
    "    * [Evaluate the Model](#17)\n",
    "* [Deep Learning Tutorial for Beginners](https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners)\n",
    "* [Artificial Neural Network with Pytorch](https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers)\n",
    "* [Convolutional Neural Network with Pytorch](https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers)\n",
    "* [Recurrent Neural Network with Pytorch](https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch)\n",
    "* [Conclusion](#18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "import warnings\n",
    "# filter warnings\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "## Loading the Data Set\n",
    "* In this part we load and visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "6884db4361a209f639cd6f3bf15231d271ecf563"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# read train \u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m      4\u001B[0m train\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[0;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[1;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[0;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "# read train \n",
    "train = pd.read_csv(\"train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7ab3a0db0c87aef2bb65fae5f564ff4b1260a96"
   },
   "outputs": [],
   "source": [
    "# read test \n",
    "test= pd.read_csv(\"test.csv\")\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "318d94f6e935a6d8210d0ac03707dfa6e3946475"
   },
   "outputs": [],
   "source": [
    "# put labels into y_train variable\n",
    "Y_train = train[\"label\"]\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8902b0312e6c047596cf27ebba554a68b82604b2"
   },
   "outputs": [],
   "source": [
    "# visualize number of digits classes\n",
    "plt.figure(figsize=(15,7))\n",
    "g = sns.countplot(Y_train, palette=\"icefire\")\n",
    "plt.title(\"Number of digit classes\")\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c9d3a1467cf82a3dff04967a9846906f9758ed4"
   },
   "outputs": [],
   "source": [
    "# plot some samples\n",
    "img = X_train.iloc[0].to_numpy()\n",
    "img = img.reshape((28,28))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.title(train.iloc[0,0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d6b119ecbe774a45656d1d157f9b33f38adf8e96"
   },
   "outputs": [],
   "source": [
    "# plot some samples\n",
    "img = X_train.iloc[3].to_numpy()\n",
    "img = img.reshape((28,28))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.title(train.iloc[3,0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74e341f4845b42101182eda3c990e3dc4dc64dff"
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "## Normalization, Reshape and Label Encoding \n",
    "* Normalization\n",
    "    * We perform a grayscale normalization to reduce the effect of illumination's differences.\n",
    "    * If we perform normalization, CNN works faster.\n",
    "* Reshape\n",
    "    * Train and test images (28 x 28) \n",
    "    * We reshape all data to 28x28x1 3D matrices.\n",
    "    * Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel. \n",
    "* Label Encoding  \n",
    "    * Encode labels to one hot vectors \n",
    "        * 2 => [0,0,1,0,0,0,0,0,0,0]\n",
    "        * 4 => [0,0,0,0,1,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f39e537f15757b5da3363c138a33e50bd78bbf49"
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "print(\"x_train shape: \",X_train.shape)\n",
    "print(\"test shape: \",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d524f6de086928158a76c54d1685a92c1802e230"
   },
   "outputs": [],
   "source": [
    "# Reshape\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "print(\"x_train shape: \",X_train.shape)\n",
    "print(\"test shape: \",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d15d35ca439dce194a96f4442c7a1c085ce24d28"
   },
   "outputs": [],
   "source": [
    "# Label Encoding \n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "111d4a1e66d823363f890f892bba39d692479663"
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "## Train Test Split\n",
    "* We split the data into train and test sets.\n",
    "* test size is 10%.\n",
    "* train size is 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "882d9dfb1bee94b2ec1e83911e3e334994d74f4b"
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_test shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_test shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cdc57350e1c251ec583093ebba18c51a537f55f"
   },
   "outputs": [],
   "source": [
    "# Some examples\n",
    "plt.imshow(X_train[2][:,:,0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "caf4b9f7fcae153ac1d4c0246b1defc9d9d30776"
   },
   "source": [
    "<a id=\"4\"></a>\n",
    "## Convolutional Neural Network \n",
    "* CNN is used for image classification, object detection \n",
    "* <a href=\"https://ibb.co/kV1j9p\"><img src=\"https://preview.ibb.co/nRkBpp/gec2.jpg\" alt=\"gec2\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "682cb6f5144794038c0bef1dc0814dde0f7fe6c0"
   },
   "source": [
    "<a id=\"5\"></a>\n",
    "### What is Convolution Operation?\n",
    "* We have some image and feature detector(3*3)\n",
    "* Feature detector does not need to be 3 by 3 matrix. It can be 5 by 5 or 7 by 7.\n",
    "* Feature detector = kernel = filter\n",
    "* Feauture detector detects features like edges or convex shapes. Example, if out input is dog, feature detector can detect features like ear or tail of the dog.\n",
    "* feature map = conv(input image, feature detector). Element wise multiplication of matrices.\n",
    "* feature map = convolved feature\n",
    "* Stride = navigating in input image.\n",
    "* We reduce the size of image. This is important bc code runs faster. However, we lost information. \n",
    "* We create multiple feature maps bc we use multiple feature detectors(filters).\n",
    "* Lets look at gimp. Edge detect: [0,10,0],[10,-4,10],[0,10,0]\n",
    "* <a href=\"https://imgbb.com/\"><img src=\"https://image.ibb.co/m4FQC9/gec.jpg\" alt=\"gec\" border=\"0\"></a>\n",
    "* After having convolution layer we use ReLU to break up linearity. Increase nonlinearity. Because images are non linear.\n",
    "* <a href=\"https://ibb.co/mVZih9\"><img src=\"https://preview.ibb.co/gbcQvU/RELU.jpg\" alt=\"RELU\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3af8fb49243719ad70016b64cd4dff6e62c413d9"
   },
   "source": [
    "<a id=\"6\"></a>\n",
    "### Same Padding\n",
    "* As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n",
    "* input size and output size are same.\n",
    "* <a href=\"https://ibb.co/jUPkUp\"><img src=\"https://preview.ibb.co/noH5Up/padding.jpg\" alt=\"padding\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6694b8ea366f974d6bd055a2915a5dc06f7a96bb"
   },
   "source": [
    "<a id=\"7\"></a>\n",
    "### Max Pooling\n",
    "* It makes down-sampling or sub-sampling (Reduces the number of parameters)\n",
    "* It makes the detection of features invariant to scale or orientation changes.\n",
    "* It reduce the amount of parameters and computation in the network, and hence to also control overfitting. \n",
    "* <a href=\"https://ibb.co/ckTjN9\"><img src=\"https://preview.ibb.co/gsNYFU/maxpool.jpg\" alt=\"maxpool\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2fb971fc473c9104a27975242a36f8e9183742c"
   },
   "source": [
    "<a id=\"8\"></a>\n",
    "### Flattening\n",
    "* <a href=\"https://imgbb.com/\"><img src=\"https://image.ibb.co/c7eVvU/flattenigng.jpg\" alt=\"flattenigng\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f437407cf18fdfacf8626baa5e76ed5d64be1a11"
   },
   "source": [
    "<a id=\"9\"></a>\n",
    "### Full Connection\n",
    "* Neurons in a fully connected layer have connections to all activations in the previous layer\n",
    "* Artificial Neural Network\n",
    "* <a href=\"https://ibb.co/hsS14p\"><img src=\"https://preview.ibb.co/evzsAU/fullyc.jpg\" alt=\"fullyc\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b290eb3f3b111d6841f8e4093277be1bde05078"
   },
   "source": [
    "<a id=\"10\"></a>\n",
    "## Implementing with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd9feb4c4dadbb8a5cc8a32b5ef582d41b5c0698"
   },
   "source": [
    "<a id=\"11\"></a>\n",
    "### Create Model\n",
    "* conv => max pool => dropout => conv => max pool => dropout => fully connected (2 layer)\n",
    "* Dropout: Dropout is a technique where randomly selected neurons are ignored during training\n",
    "* <a href=\"https://ibb.co/jGcvVU\"><img src=\"https://preview.ibb.co/e7yPPp/dropout.jpg\" alt=\"dropout\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c441d7b3852cee5d3636272d4da2f96b169f81ac"
   },
   "outputs": [],
   "source": [
    "# \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "#\n",
    "model.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "# fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a432df491777ca0019db6f6b972581f2c5bd9f9"
   },
   "source": [
    "<a id=\"12\"></a>\n",
    "### Define Optimizer   \n",
    "* Adam optimizer: Change the learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "607a02b42636e3115a1ac7a8edcadf61cf5ea1b0"
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91bf542a979c5b191c534876186bf31e70ec7f06"
   },
   "source": [
    "<a id=\"13\"></a>\n",
    "### Compile Model\n",
    "* categorical crossentropy\n",
    "* We make binary cross entropy at previous parts and in machine learning tutorial\n",
    "* At this time we use categorical crossentropy. That means that we have multi class.\n",
    "* <a href=\"https://ibb.co/jm1bpp\"><img src=\"https://preview.ibb.co/nN3ZaU/cce.jpg\" alt=\"cce\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d1eefc68470b4cdcec04c2570651da3d97676d0"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d5d8fea4cbb9b53cf1bb5089357a33dc179ee981"
   },
   "source": [
    "<a id=\"14\"></a>\n",
    "### Epochs and Batch Size\n",
    "* Say you have a dataset of 10 examples (or samples). You have a **batch size** of 2, and you've specified you want the algorithm to run for 3 **epochs**. Therefore, in each epoch, you have 5 **batches** (10/2 = 5). Each batch gets passed through the algorithm, therefore you have 5 iterations **per epoch**.\n",
    "* reference: https://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a237feb5e53ecbc8799101cb6e699877faafde77"
   },
   "outputs": [],
   "source": [
    "epochs = 10  # for better result increase the epochs\n",
    "batch_size = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e87c60e45759e0c52c2b72ee562fdb964c8008d5"
   },
   "source": [
    "<a id=\"15\"></a>\n",
    "### Data Augmentation\n",
    "* To avoid overfitting problem, we need to expand artificially our handwritten digit dataset\n",
    "* Alter the training data with small transformations to reproduce the variations of digit.\n",
    "* For example, the number is not centered The scale is not the same (some who write with big/small numbers) The image is rotated.\n",
    "* <a href=\"https://ibb.co/k24CUp\"><img src=\"https://preview.ibb.co/nMxXUp/augment.jpg\" alt=\"augment\" border=\"0\"></a>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c339fa7d06e9b73a519ca661bed19de482707d1f"
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # dimesion reduction\n",
    "        rotation_range=5,  # randomly rotate images in the range 5 degrees\n",
    "        zoom_range = 0.8, # Randomly zoom image 10%\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally 10%\n",
    "        height_shift_range=0.1,  # randomly shift images vertically 10%\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e42e43f1b3b9e6da0d99dafff8f4a4b514a07f4c"
   },
   "source": [
    "<a id=\"16\"></a>\n",
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b2957bb8976a25cdbbbdc3110d68c5035a9773c"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "debd5424728e11aa30a8513ac7b4f7377193a2da"
   },
   "source": [
    "<a id=\"17\"></a>\n",
    "### Evaluate the model\n",
    "* Test Loss visualization\n",
    "* Confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "180a06f7ae01e69117c6c8258411cfe1b9b7b991"
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6586e37bd470db822086e191a90388e7175d504f"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sns\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9409bc6a7e905d5887c8eec8d056c9f015bf4878"
   },
   "source": [
    "<a id=\"18\"></a>\n",
    "## Conclusion\n",
    "* http://scs.ryerson.ca/~aharley/vis/conv/flat.html\n",
    "* HW\n",
    "* If you have any question I will be very happy to hear it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}